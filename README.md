**CLEAN & DIRECT README.md** - Copy & paste as-is:

```markdown
# YC Companies Intelligence Platform

A production-grade data pipeline that scrapes Y Combinator companies, stores structured data in PostgreSQL, and provides analytics through a Next.js frontend.

## ğŸ¯ Project Overview

This platform scrapes **1000+ Y Combinator funded startups** with 10+ data fields per company, implements incremental data synchronization with deduplication, and exposes comprehensive analytics through REST APIs and an interactive dashboard.

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   YC Website    â”‚â”€â”€â”€â”€â–¶â”‚   Python Scraper â”‚â”€â”€â”€â”€â–¶â”‚  PostgreSQL     â”‚
â”‚   (Algolia)     â”‚     â”‚   (asyncio)      â”‚     â”‚   (Neon Cloud)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â”œâ”€ list_scraper.py
                               â”œâ”€ detail_scraper.py
                               â”œâ”€ website_enrichment.py
                               â””â”€ main_scraper.py
                                      â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                            â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Next.js APIs  â”‚         â”‚  Next.js Pages â”‚
                â”‚  (4 endpoints) â”‚         â”‚  (3 pages)     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                          â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Frontend Dashboard  â”‚
                        â”‚  (React + Tailwind)  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


## âœ¨ Features

### Backend (Python Scraper)
- Scrapes all YC companies from Algolia API
- Detail page extraction with BeautifulSoup
- Incremental sync with SHA256 data deduplication
- Website enrichment (careers/blog/email detection)
- Async processing with aiohttp (20 concurrent requests)
- Performance metrics (per-company timing)
- Comprehensive logging (scraper.log)
- Error handling & graceful degradation

### Database (PostgreSQL)
- **companies** - 1000 rows with company metadata
- **company_snapshots** - 1000+ historical records with deduplication
- **company_web_enrichment** - 998 enriched records
- **scrape_runs** - Performance metrics and execution history

### APIs (REST)
- `GET /api/companies` - Paginated list with search & filters
- `GET /api/companies/:id` - Company details + snapshot history
- `GET /api/analytics` - Stage/country/tag distribution
- `GET /api/scrape-runs` - Scrape execution history

### Frontend (Next.js)
- Company Explorer - Search, filter, paginate 1000 companies
- Company Detail Page - Full history, enrichment data, timeline
- Analytics Dashboard - Charts, metrics, company table

## ğŸš€ Tech Stack

**Backend:**
- Python 3.9+ (requests, BeautifulSoup4, psycopg2, asyncio, aiohttp)

**Database:**
- PostgreSQL 15 (Neon Cloud recommended)

**Frontend:**
- Next.js 16 (TypeScript, React 19, Tailwind CSS, Recharts)

**Deployment:**
- Vercel (frontend)
- Neon PostgreSQL (database)
- GitHub (source control)

## ğŸ“ Quick Start

### Local Development

```bash
# Backend
cd yc-intel
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
python scraper/main_scraper.py

# Frontend
cd yc-frontend
npm install
npm run dev
# Visit http://localhost:3000
````

### Vercel Deployment

1. Push to GitHub
2. Import repo in Vercel
3. Add `POSTGRES_URL` environment variable (Neon connection string)
4. Deploy

## ğŸ”„ How It Works

1. **Scrapes** all YC companies from Algolia
2. **Stores** company data with SHA256 hashing for deduplication
3. **Tracks** changes in snapshots table
4. **Enriches** websites for careers/blog/email
5. **Logs** all metrics to scrape_runs
6. **Exposes** 4 REST APIs
7. **Displays** analytics through Next.js frontend

## ğŸ“Š Data Captured

- Company name, domain, location
- Funding stage, batch, employee range
- Tags, description, website features
- Historical change tracking
- Performance metrics per scrape run

## ğŸ¯ Requirements Met

âœ… Scrape 1000+ companies (10+ fields each)
âœ… Incremental sync with deduplication
âœ… Historical snapshots with timestamps
âœ… Website enrichment (careers/blog/email)
âœ… Performance metrics per company
âœ… Master scraper orchestration
âœ… Inactive company marking
âœ… 4 REST API endpoints
âœ… 3 frontend pages
âœ… Analytics dashboard
âœ… Comprehensive logging
âœ… Error handling & graceful degradation
âœ… Production-ready deployment

## ğŸ“„ License

MIT

## ğŸ‘¨â€ğŸ’» Author

Abhijith kp

---
